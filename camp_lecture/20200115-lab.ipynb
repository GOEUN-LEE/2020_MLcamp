{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20200115-lab.ipynb","provenance":[],"authorship_tag":"ABX9TyMcJ/aJeIYflFbCYsTdngY3"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"z63P4niouk2g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"5e5ea25c-1e92-4977-94fb-44d0932ad5a9","executionInfo":{"status":"ok","timestamp":1579084299578,"user_tz":-540,"elapsed":702,"user":{"displayName":"이고은학부생","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD7Hhpz51CZiAt-pFqVW_whashy8di01qX2cWMt=s64","userId":"09774315254356044053"}}},"source":["### Decision Tree\n","# Import libraries\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","import warnings\n","warnings.simplefilter(action='ignore',category=FutureWarning)\n","warnings.simplefilter(action='ignore',category=DeprecationWarning)\n","\n","# Classification metrics\n","from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, log_loss)\n","\n","# Load the Iris dataset\n","from sklearn.datasets import load_iris\n","# iris_dataset=load_iris()\n","# print(iris_dataset.DESCR)\n","X,y = load_iris(return_X_y= True)\n","\n","# STEP1. Separating training and testing datasets\n","X_tr,X_ts,y_tr,y_ts = train_test_split(X,y,test_size=0.4, random_state=777)\n","\n","# STEP2&3. Optimizing hyperparameters via cross validation\n","# Instantiate a model object\n","clf = DecisionTreeClassifier()\n","\n","# Set a search range\n","parameters = {'criterion':['gini','entropy']}\n","\n","# Find the best hyperparameters using GridSearchCV\n","gridsearch = GridSearchCV(clf, parameters, scoring = 'accuracy', cv=5)\n","gridsearch.fit(X_tr,y_tr)\n","\n","# Show the best hyperparameter\n","print(f'gridsearch.best_params_ = {gridsearch.best_params_}')\n","\n","# The best model is stored in 'best_clf'\n","best_clf = gridsearch.best_estimator_\n","best_clf\n","\n","# STEP4. Model performance\n","y_pred = best_clf.predict(X_ts)\n","test_acc = accuracy_score(y_ts, y_pred)\n","print(f'test_acc = {test_acc}')\n","\n","# STEP5. Train final model on full dataset(optional step)\n","final_model = DecisionTreeClassifier(**gridsearch.best_params_)\n","final_model.fit(X,y)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["gridsearch.best_params_ = {'criterion': 'gini'}\n","test_acc = 0.9333333333333333\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n","                       max_depth=None, max_features=None, max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, presort='deprecated',\n","                       random_state=None, splitter='best')"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"p3ZI9Kt6u7w3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"864dd99a-67a0-4f97-d314-16b56a1d8d6f","executionInfo":{"status":"ok","timestamp":1579084461065,"user_tz":-540,"elapsed":6833,"user":{"displayName":"이고은학부생","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD7Hhpz51CZiAt-pFqVW_whashy8di01qX2cWMt=s64","userId":"09774315254356044053"}}},"source":["### 5.1 Random Forest using sklearn\n","# Import libraries\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import tree\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","import warnings\n","warnings.simplefilter(action='ignore',category=FutureWarning)\n","warnings.simplefilter(action='ignore',category=DeprecationWarning)\n","\n","# Classification metrics\n","from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, log_loss)\n","\n","# Load the Iris dataset\n","from sklearn.datasets import load_iris\n","# iris_dataset=load_iris()\n","# print(iris_dataset.DESCR)\n","X,y = load_iris(return_X_y= True)\n","\n","# STEP1. Separating training and testing datasets\n","X_tr,X_ts,y_tr,y_ts = train_test_split(X,y,test_size=0.4, random_state=777)\n","\n","# STEP2&3. Optimizing hyperparameters via cross validation\n","# Instantiate a model object\n","clf = RandomForestClassifier()\n","\n","# Set a search range\n","parameters = {'n_estimators':[100,150,200], 'criterion':['gini','entropy']}\n","\n","# Find the best hyperparameters using GridSearchCV\n","gridsearch = GridSearchCV(clf, parameters, scoring = 'accuracy', cv=5)\n","gridsearch.fit(X_tr,y_tr)\n","\n","# Show the best hyperparameter\n","print(f'gridsearch.best_params_ = {gridsearch.best_params_}')\n","\n","# The best model is stored in 'best_clf'\n","best_clf = gridsearch.best_estimator_\n","best_clf\n","\n","# STEP4. Model performance\n","y_pred = best_clf.predict(X_ts)\n","test_acc = accuracy_score(y_ts, y_pred)\n","print(f'test_acc = {test_acc}')\n","\n","# STEP5. Train final model on full dataset(optional step)\n","final_model = RandomForestClassifier(**gridsearch.best_params_)\n","final_model.fit(X,y)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["gridsearch.best_params_ = {'criterion': 'gini', 'n_estimators': 100}\n","test_acc = 0.9333333333333333\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=None, max_features='auto',\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=100,\n","                       n_jobs=None, oob_score=False, random_state=None,\n","                       verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"GMXF3KJJxGA4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"outputId":"70fc20a0-5b6b-4271-9615-1d612543becb","executionInfo":{"status":"ok","timestamp":1579084496394,"user_tz":-540,"elapsed":1057,"user":{"displayName":"이고은학부생","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD7Hhpz51CZiAt-pFqVW_whashy8di01qX2cWMt=s64","userId":"09774315254356044053"}}},"source":["### 5.2 Logistic Regression\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# load a dataset\n","X,y = load_iris(return_X_y=True)\n","\n","# STEP1. Get training and testing datasets\n","X_tr,X_ts,y_tr,y_ts = train_test_split(X,y,test_size=0.4,random_state=777)\n","\n","# STEP1-1. Data Normalization\n","normalizer = MinMaxScaler(feature_range=(0,1))\n","normalizer.fit(X_tr)\n","X_tr_normalized = normalizer.transform(X_tr)\n","X_ts_normalized = normalizer.transform(X_ts)\n","\n","# show first 5 instances\n","print('Before normalization :\\n',X_tr[:5])\n","print('After normalization :\\n',X_tr_normalized[:5])\n","\n","# STEP2. Use GridSearchCV to find optimal hyperparameter values\n","clf = LogisticRegression(max_iter=5000)\n","parameters = {'penalty':['l2'],'C':[10e-5,10e-3,10e-2,10e-1,10e0,10e1,10e2,10e3,10e5]}\n","gridsearch = GridSearchCV(clf, parameters, scoring = 'accuracy', cv = 5)\n","gridsearch.fit(X_tr_normalized, y_tr)\n","print(f'gridsearch.best_params_ = {gridsearch.best_params_}')\n","\n","# STEP3. Get model with best hyperparameter\n","best_clf = gridsearch.best_estimator_\n","\n","# STEP4. Get best model performance from testing set\n","y_pred = best_clf.predict(X_ts_normalized)\n","test_acc = accuracy_score(y_ts, y_pred)\n","print(f'test_acc = {test_acc}')\n","\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Before normalization :\n"," [[5.5 2.4 3.7 1. ]\n"," [6.3 2.8 5.1 1.5]\n"," [4.6 3.1 1.5 0.2]\n"," [4.8 3.1 1.6 0.2]\n"," [4.5 2.3 1.3 0.3]]\n","After normalization :\n"," [[0.34375    0.16666667 0.46296296 0.375     ]\n"," [0.59375    0.33333333 0.72222222 0.58333333]\n"," [0.0625     0.45833333 0.05555556 0.04166667]\n"," [0.125      0.45833333 0.07407407 0.04166667]\n"," [0.03125    0.125      0.01851852 0.08333333]]\n","gridsearch.best_params_ = {'C': 100.0, 'penalty': 'l2'}\n","test_acc = 0.9833333333333333\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mCPj-5HMxTl_","colab_type":"code","colab":{}},"source":["### Boosted Logistic Regression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","\n","def test_boosted_logreg(K,X_tr,y_tr,X_ts,y_ts):\n","  base = LogisticRegression(penalty='l2',max_iter=5000)\n","  clf = AdaBoostClassifier(base, n_estimators=K)\n","  parameters = {'base_estimator__C':[10e-5, 10e-3, 10e-2, 10e-1, 10e0, 10e1, 10e2, 10e3, 10e5]}\n","  gridsearch = GridSearchCV(clf,parameters,scoring='accuracy',cv=5)\n","  gridsearch.fit(X_tr_normalized,y_tr)\n","  best_clf = gridsearch.best_estimator_\n","  y_pred = best_clf.predict(X_ts)\n","  test_acc = accuracy_score(y_ts, y_pred)\n","\n","  return best_clf, y_pred, test_acc\n","\n","  "],"execution_count":0,"outputs":[]}]}